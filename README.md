# DetecÃ§Ã£o de Fraudes em Seguros Automotivos com Machine Learning e XAI

[![Python 3.11](https://img.shields.io/badge/Python-3.11-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![ICMC-USP](https://img.shields.io/badge/ICMC-USP-green.svg)](https://www.icmc.usp.br/)

> **MBA em InteligÃªncia Artificial e Big Data - ICMC/USP**  
> **Autor:** Eduardo Barbante Rodrigues  
> **Orientadora:** Profa. Dra. Cibele Maria Russo Novelli  
> **Ano:** 2025

---

## ğŸ“‹ Sobre o Projeto

Este repositÃ³rio contÃ©m o cÃ³digo-fonte do Trabalho de ConclusÃ£o de Curso (TCC) que propÃµe um sistema de detecÃ§Ã£o de fraudes em seguros automotivos baseado em aprendizado de mÃ¡quina, integrando trÃªs perspectivas complementares:

1. **Desempenho Preditivo** - MÃ©tricas robustas para dados desbalanceados (MCC, G-Mean, Kappa)
2. **Viabilidade EconÃ´mica** - AnÃ¡lise de ROI e BenefÃ­cio LÃ­quido
3. **Interpretabilidade** - Explicabilidade das decisÃµes via SHAP (XAI)

### ğŸ† Resultados Principais

| MÃ©trica | Valor |
|---------|-------|
| **Modelo CampeÃ£o** | CatBoost + SMOTEENN |
| **MCC** | 0.3144 |
| **Recall (Taxa de Captura)** | 52.7% |
| **ROI** | 943% |
| **BenefÃ­cio LÃ­quido** | R$ 3.508.000 |

---

## ğŸ“ Estrutura do RepositÃ³rio

```
tcc-fraud-detection-autoinsurance/
â”‚
â”œâ”€â”€ README.md                          # Este arquivo
â”œâ”€â”€ LICENSE                            # LicenÃ§a MIT
â”‚
â”œâ”€â”€ src/                               # CÃ³digo-fonte principal
â”‚   â”œâ”€â”€ fraud_detection.py             # Pipeline completo (treino, validaÃ§Ã£o, teste)
â”‚   â””â”€â”€ fraud_detection_shap_analysis.py  # AnÃ¡lise SHAP (interpretabilidade)
â”‚
â”œâ”€â”€ requirements/                      # DependÃªncias separadas por ambiente
â”‚   â”œâ”€â”€ requirements_main.txt          # Pipeline principal
â”‚   â””â”€â”€ requirements_shap.txt          # AnÃ¡lise SHAP (ambiente separado)
â”‚
â”œâ”€â”€ scripts/                           # Scripts auxiliares
â”‚   â”œâ”€â”€ setup_main_env.sh              # Setup ambiente principal (Linux/Mac)
â”‚   â”œâ”€â”€ setup_shap_env.sh              # Setup ambiente SHAP (Linux/Mac)
â”‚   â”œâ”€â”€ setup_main_env.bat             # Setup ambiente principal (Windows)
â”‚   â””â”€â”€ setup_shap_env.bat             # Setup ambiente SHAP (Windows)
â”‚
â”œâ”€â”€ data/                              # Dados (nÃ£o versionados)
â”‚   â””â”€â”€ .gitkeep
â”‚
â”œâ”€â”€ outputs/                           # Resultados gerados (nÃ£o versionados)
â”‚   â””â”€â”€ .gitkeep
â”‚
â””â”€â”€ docs/                              # DocumentaÃ§Ã£o adicional
    â””â”€â”€ COMPATIBILITY_NOTES.md         # Notas sobre compatibilidade de versÃµes
```

---

## ğŸš€ Quick Start

### PrÃ©-requisitos

- Python 3.11+
- Git

### 1. Clone o RepositÃ³rio

```bash
git clone https://github.com/edurodrigues-usp/tcc-fraud-detection-autoinsurance.git
cd tcc-fraud-detection-autoinsurance
```

### 2. O Dataset jÃ¡ estÃ¡ incluÃ­do! âœ…

O arquivo `data/fraud_oracle.csv` jÃ¡ estÃ¡ no repositÃ³rio (3.5MB).

Fonte original: [Kaggle - Vehicle Insurance Claim Fraud Detection](https://www.kaggle.com/datasets/shivamb/vehicle-claim-fraud-detection)

### 3. Configure os Ambientes

âš ï¸ **IMPORTANTE:** Este projeto requer **dois ambientes virtuais separados** devido a incompatibilidades entre versÃµes de bibliotecas (ver [Notas de Compatibilidade](docs/COMPATIBILITY_NOTES.md)).

#### Ambiente Principal (Pipeline de ML)

```bash
# Linux/Mac
python -m venv venv_main
source venv_main/bin/activate
pip install -r requirements/requirements_main.txt

# Windows
python -m venv venv_main
venv_main\Scripts\activate
pip install -r requirements/requirements_main.txt
```

#### Ambiente SHAP (Interpretabilidade)

âš ï¸ **IMPORTANTE:** Este ambiente usa NumPy 2.0+ (diferente do Main que usa 1.26.4).

```bash
# Linux/Mac
python3 -m venv venv_shap
source venv_shap/bin/activate
pip install -r requirements/requirements_shap.txt

# Windows
python -m venv venv_shap
venv_shap\Scripts\activate
pip install -r requirements/requirements_shap.txt

# Windows (se tiver mÃºltiplas versÃµes do Python)
py -3.11 -m venv venv_shap
venv_shap\Scripts\activate
pip install -r requirements/requirements_shap.txt
```

> **Por quÃª dois ambientes?** PyCaret requer NumPy 1.26.4, mas SHAP 0.50.0 requer NumPy >= 2.0. Ver [docs/COMPATIBILITY_NOTES.md](docs/COMPATIBILITY_NOTES.md) para detalhes.

### 4. Execute o Pipeline

#### Etapa 1: Treinar e Avaliar Modelos

```bash
# Ativar ambiente principal
source venv_main/bin/activate  # Linux/Mac
# ou
venv_main\Scripts\activate     # Windows

# Executar pipeline (modo FAST para teste rÃ¡pido)
cd src
python fraud_detection.py

# Para execuÃ§Ã£o completa (TCC), edite FAST_MODE = False no script
```

**SaÃ­das geradas em `outputs/`:**
- `best_model_final_full.pkl` - Modelo completo para SHAP
- `best_model_final_light.pkl` - Modelo leve para deploy
- `model_comparison_FINAL_V3.csv` - ComparaÃ§Ã£o de todos os modelos
- `champion_cv_results.csv` - Resultados da validaÃ§Ã£o cruzada

#### Etapa 2: AnÃ¡lise SHAP (Interpretabilidade)

```bash
# âš ï¸ TROCAR para ambiente SHAP
deactivate
source venv_shap/bin/activate  # Linux/Mac
# ou
venv_shap\Scripts\activate     # Windows

# Executar anÃ¡lise SHAP (da pasta src/)
cd src
python fraud_detection_shap_analysis.py
```

**SaÃ­das geradas em `outputs/shap_results/`:**
- 23 visualizaÃ§Ãµes PNG (summary plots, waterfalls, dependence plots)
- 1 HTML interativo (force plot)
- CSVs com valores SHAP e importÃ¢ncias

---

## ğŸ“Š Metodologia

### Pipeline de Dados

```
Dataset Bruto (15.420 registros)
        â”‚
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  LIMPEZA E DIVISÃƒO ESTRATIFICADA    â”‚
â”‚  Train (60%) / Val (20%) / Test (20%)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  FEATURE ENGINEERING (fit no train) â”‚
â”‚  â€¢ Isolation Forest (anomaly score) â”‚
â”‚  â€¢ Target Encoding (fraud rates)    â”‚
â”‚  â€¢ VariÃ¡veis de interaÃ§Ã£o           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  MODELAGEM COM BALANCEAMENTO        â”‚
â”‚  â€¢ SMOTE / ADASYN / SMOTEENN        â”‚
â”‚  â€¢ OtimizaÃ§Ã£o Bayesiana (Optuna)    â”‚
â”‚  â€¢ Threshold Tuning (Kappa)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  AVALIAÃ‡ÃƒO FINAL                    â”‚
â”‚  â€¢ MÃ©tricas tÃ©cnicas (MCC, G-Mean)  â”‚
â”‚  â€¢ MÃ©tricas de negÃ³cio (ROI)        â”‚
â”‚  â€¢ Interpretabilidade (SHAP)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Algoritmos Avaliados

| Categoria | Algoritmos |
|-----------|------------|
| **Baselines** | DummyClassifier, Logistic Regression |
| **Ensemble/Boosting** | Random Forest, XGBoost, LightGBM, CatBoost |

### TÃ©cnicas de Balanceamento

- SMOTE (Synthetic Minority Over-sampling)
- ADASYN (Adaptive Synthetic Sampling)
- SMOTEENN (SMOTE + Edited Nearest Neighbors)
- SMOTETomek (SMOTE + Tomek Links)

---

## ğŸ“ˆ Resultados Detalhados

### Top 5 Modelos (ValidaÃ§Ã£o)

| Rank | Modelo | Sampler | Score Composto | MCC | Recall |
|------|--------|---------|----------------|-----|--------|
| 1 | CatBoost | SMOTEENN | 0.4325 | 0.3144 | 52.7% |
| 2 | LightGBM | SMOTETomek | 0.4256 | 0.3087 | 50.5% |
| 3 | CatBoost | Nenhum | 0.4218 | 0.3151 | 44.0% |
| 4 | CatBoost | SMOTETomek | 0.4208 | 0.3106 | 45.7% |
| 5 | XGBoost | SMOTETomek | 0.4198 | 0.3073 | 46.7% |

### AnÃ¡lise SHAP - Top 5 VariÃ¡veis

1. **Fault_Policy_Holder** - Culpa do segurado (preditor dominante)
2. **Is_Third_Party_Fault** - Culpa de terceiro
3. **BasePolicy_fraud_rate** - Taxa histÃ³rica de fraude da apÃ³lice
4. **Make_fraud_rate** - Taxa histÃ³rica de fraude por fabricante
5. **Year** - Ano do sinistro

---

## âš ï¸ Notas de Compatibilidade

Este projeto requer **dois ambientes virtuais separados** devido a conflitos entre:
- **PyCaret 3.3.2** â†’ requer NumPy 1.26.4
- **SHAP 0.50.0** â†’ requer NumPy >= 2.0

**SoluÃ§Ã£o:** Ambiente Main (treino) separado do Ambiente SHAP (interpretabilidade).

Detalhes completos em [docs/COMPATIBILITY_NOTES.md](docs/COMPATIBILITY_NOTES.md).

---

## ğŸ“š ReferÃªncias

- **Dataset:** [Fraud Oracle - Kaggle](https://www.kaggle.com/datasets/shivamb/vehicle-claim-fraud-detection)
- **SHAP:** Lundberg & Lee (2017) - [A Unified Approach to Interpreting Model Predictions](https://arxiv.org/abs/1705.07874)
- **MÃ©tricas Robustas:** Huayanay, BazÃ¡n & Russo (2024) - Performance of evaluation metrics for classification in imbalanced data

---

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ licenciado sob a licenÃ§a MIT - veja o arquivo [LICENSE](LICENSE) para detalhes.

---

## ğŸ‘¤ Autor

**Eduardo Barbante Rodrigues**
- LinkedIn: [/in/eduardorodrigues01](https://linkedin.com/in/eduardorodrigues01)
- GitHub: [@edurodrigues-usp](https://github.com/edurodrigues-usp)

---

## ğŸ™ Agradecimentos

- Profa. Dra. Cibele Maria Russo Novelli (Orientadora)
- Profa. Dra. Solange Oliveira Rezende
- ICMC-USP
- Porto Seguro (contexto profissional)
