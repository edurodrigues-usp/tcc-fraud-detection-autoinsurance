# ğŸ“ TCC: DetecÃ§Ã£o de fraudes em seguros automotivos com aprendizado de mÃ¡quina e inteligÃªncia artificial explicÃ¡vel (XAI)

[![Python](https://img.shields.io/badge/Python-3.11-blue.svg)](https://www.python.org/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)
[![Institution](https://img.shields.io/badge/Institution-ICMC--USP-red.svg)](https://www.icmc.usp.br/)

**Trabalho de ConclusÃ£o de Curso (TCC)**  
**Autor:** Eduardo Barbante Rodrigues  
**Orientadora:** Profa. Dra. Cibele M. Russo  
**InstituiÃ§Ã£o:** Instituto de CiÃªncias MatemÃ¡ticas e de ComputaÃ§Ã£o (ICMC-USP)  
**Ano:** 2025

---

## ğŸ“‹ Sobre o Projeto

Este repositÃ³rio contÃ©m o cÃ³digo-fonte completo, dados e documentaÃ§Ã£o do Trabalho de ConclusÃ£o de Curso que propÃµe um sistema de detecÃ§Ã£o de fraudes em seguros automotivos utilizando tÃ©cnicas de aprendizado de mÃ¡quina. O trabalho integra trÃªs perspectivas de avaliaÃ§Ã£o:

- **ğŸ¯ TÃ©cnica:** MÃ©tricas especializadas para dados desbalanceados (MCC, G-Mean, Kappa)
- **ğŸ’° EconÃ´mica:** AnÃ¡lise de viabilidade financeira (ROI, BenefÃ­cio LÃ­quido)
- **ğŸ” Interpretabilidade:** TÃ©cnicas de XAI (SHAP) para transparÃªncia das decisÃµes

### ğŸ“Š Principais Resultados

| MÃ©trica | Valor |
|---------|-------|
| **MCC** | 0,3144 |
| **G-Mean** | 0,69 |
| **Kappa** | 0,2924 |
| **Recall** | 52,72% |
| **Precision** | 26,08% |
| **ROI** | **943%** |
| **BenefÃ­cio LÃ­quido** | **R$ 3.508.000** |

**Modelo CampeÃ£o:** CatBoost + SMOTEENN  
**Ganho vs. Baseline:** +23,9% (R$ 676.000)

---

## ğŸ—‚ï¸ Estrutura do RepositÃ³rio

```
tcc-fraud-detection-autoinsurance/
â”‚
â”œâ”€â”€ data/                          # Dados
â”‚   â”œâ”€â”€ fraud_oracle.csv          # Dataset principal (Kaggle)
â”‚   â””â”€â”€ README.md                 # DescriÃ§Ã£o dos dados
â”‚
â”œâ”€â”€ src/                          # CÃ³digo-fonte
â”‚   â”œâ”€â”€ preprocessing/            # PrÃ©-processamento
â”‚   â”‚   â”œâ”€â”€ feature_engineering.py
â”‚   â”‚   â””â”€â”€ data_cleaning.py
â”‚   â”‚
â”‚   â”œâ”€â”€ models/                   # Modelagem
â”‚   â”‚   â”œâ”€â”€ train_pipeline.py
â”‚   â”‚   â”œâ”€â”€ optimization.py
â”‚   â”‚   â””â”€â”€ evaluation.py
â”‚   â”‚
â”‚   â”œâ”€â”€ interpretability/         # AnÃ¡lise SHAP
â”‚   â”‚   â”œâ”€â”€ shap_analysis.py
â”‚   â”‚   â””â”€â”€ shap_visualizations.py
â”‚   â”‚
â”‚   â””â”€â”€ utils/                    # UtilitÃ¡rios
â”‚       â”œâ”€â”€ metrics.py
â”‚       â””â”€â”€ plots.py
â”‚
â”œâ”€â”€ notebooks/                    # Jupyter Notebooks
â”‚   â”œâ”€â”€ 01_exploratory_analysis.ipynb
â”‚   â”œâ”€â”€ 02_feature_engineering.ipynb
â”‚   â”œâ”€â”€ 03_model_training.ipynb
â”‚   â””â”€â”€ 04_shap_analysis.ipynb
â”‚
â”œâ”€â”€ models/                       # Modelos treinados
â”‚   â”œâ”€â”€ best_model_FINAL_V3.pkl
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ results/                      # Resultados
â”‚   â”œâ”€â”€ figures/                  # Figuras para o TCC
â”‚   â”œâ”€â”€ tables/                   # Tabelas (CSVs)
â”‚   â””â”€â”€ shap_results/            # AnÃ¡lises SHAP
â”‚
â”œâ”€â”€ config/                       # ConfiguraÃ§Ãµes
â”‚   â”œâ”€â”€ model_config.yaml
â”‚   â””â”€â”€ optuna_config.yaml
â”‚
â”œâ”€â”€ scripts/                      # Scripts utilitÃ¡rios
â”‚   â”œâ”€â”€ setup_environment.bat     # Windows
â”‚   â”œâ”€â”€ setup_environment.sh      # Linux/Mac
â”‚   â””â”€â”€ run_full_pipeline.py
â”‚
â”œâ”€â”€ docs/                         # DocumentaÃ§Ã£o
â”‚   â”œâ”€â”€ INSTALL.md               # InstruÃ§Ãµes de instalaÃ§Ã£o
â”‚   â”œâ”€â”€ USAGE.md                 # Guia de uso
â”‚   â””â”€â”€ METHODOLOGY.md           # Metodologia detalhada
â”‚
â”œâ”€â”€ requirements.txt              # DependÃªncias principais
â”œâ”€â”€ requirements_shap.txt         # Ambiente SHAP (separado)
â”œâ”€â”€ .gitignore                    # Arquivos ignorados
â”œâ”€â”€ LICENSE                       # LicenÃ§a MIT
â””â”€â”€ README.md                     # Este arquivo
```

---

## ğŸš€ InÃ­cio RÃ¡pido

### 1ï¸âƒ£ **PrÃ©-requisitos**

- Python 3.11+
- Git
- 4 GB RAM mÃ­nimo (recomendado: 8 GB)
- 2 GB espaÃ§o em disco

### 2ï¸âƒ£ **Clonar RepositÃ³rio**

```bash
git clone https://github.com/seu-usuario/tcc-fraud-detection-autoinsurance.git
cd tcc-fraud-detection-autoinsurance
```

### 3ï¸âƒ£ **Criar Ambiente Virtual**

#### Windows:
```bash
python -m venv venv
venv\Scripts\activate
```

#### Linux/Mac:
```bash
python3 -m venv venv
source venv/bin/activate
```

### 4ï¸âƒ£ **Instalar DependÃªncias**

#### Ambiente Principal (treinamento):
```bash
pip install -r requirements.txt
```

#### Ambiente SHAP (interpretabilidade - separado):
```bash
python -m venv shap_env
shap_env\Scripts\activate  # Windows
# source shap_env/bin/activate  # Linux/Mac
pip install -r requirements_shap.txt
```

**âš ï¸ Importante:** Ambientes separados para evitar conflitos de dependÃªncias!

### 5ï¸âƒ£ **Executar Pipeline Completo**

```bash
python scripts/run_full_pipeline.py
```

**Tempo estimado:** ~45-60 minutos

**SaÃ­da:**
- Modelo treinado: `models/best_model_FINAL_V3.pkl`
- MÃ©tricas: `results/tables/model_comparison.csv`
- Figuras: `results/figures/`

---

## ğŸ“– Guias Detalhados

### ğŸ”§ [InstalaÃ§Ã£o Completa](docs/INSTALL.md)
InstruÃ§Ãµes detalhadas de instalaÃ§Ã£o em diferentes sistemas operacionais.

### ğŸ“˜ [Guia de Uso](docs/USAGE.md)
Como executar cada componente do sistema separadamente.

### ğŸ§ª [Metodologia](docs/METHODOLOGY.md)
ExplicaÃ§Ã£o detalhada das tÃ©cnicas utilizadas.

---

## ğŸ¯ Reproduzindo os Resultados do TCC

### Passo 1: Feature Engineering

```bash
python src/preprocessing/feature_engineering.py
```

**SaÃ­da:** `data/processed/fraud_oracle_engineered.csv`

### Passo 2: Treinamento e OtimizaÃ§Ã£o

```bash
python src/models/train_pipeline.py --optimize
```

**Tempo:** ~30-40 minutos  
**SaÃ­da:** Modelo otimizado com Optuna

### Passo 3: AvaliaÃ§Ã£o EconÃ´mica

```bash
python src/models/evaluation.py --economic
```

**SaÃ­da:** Tabelas e figuras de anÃ¡lise econÃ´mica

### Passo 4: AnÃ¡lise SHAP

```bash
# Ativar ambiente SHAP
shap_env\Scripts\activate

# Executar anÃ¡lise
python src/interpretability/shap_analysis.py
```

**Tempo:** ~8-10 minutos  
**SaÃ­da:** 25 visualizaÃ§Ãµes SHAP

---

## ğŸ“Š Dataset

### Fraud Oracle Dataset

**Fonte:** [Kaggle - Fraud Oracle Dataset](https://www.kaggle.com/datasets/mastmustu/fraud-oracle-dataset)

**CaracterÃ­sticas:**
- **InstÃ¢ncias:** 15.420
- **Features:** 33 (originais)
- **Target:** FraudFound_P (binÃ¡rio)
- **Desbalanceamento:** ~6% fraudes
- **Tamanho:** 3.6 MB

**DivisÃ£o:**
- Treino: 9.252 (60%)
- ValidaÃ§Ã£o: 3.084 (20%)
- Teste: 3.084 (20%)

### Feature Engineering

O pipeline aplica 154 features derivadas:
- Target Encoding
- Taxas de fraude por categoria
- DetecÃ§Ã£o de anomalias (Isolation Forest)
- VariÃ¡veis temporais
- InteraÃ§Ãµes entre features

**Detalhes:** Ver `src/preprocessing/feature_engineering.py`

---

## ğŸ† Modelo CampeÃ£o

### Arquitetura

**Algoritmo:** CatBoost  
**Balanceamento:** SMOTEENN  
**OtimizaÃ§Ã£o:** Optuna (100 trials)  
**MÃ©trica de OtimizaÃ§Ã£o:** Kappa de Cohen

### HiperparÃ¢metros

```yaml
learning_rate: 0.05
depth: 6
iterations: 500
l2_leaf_reg: 3
border_count: 128
random_strength: 1
```

### Pipeline Completo

```
Raw Data â†’ Feature Engineering â†’ SMOTEENN â†’ CatBoost â†’ Threshold Tuning â†’ PrediÃ§Ãµes
```

---

## ğŸ“ˆ AnÃ¡lise de Interpretabilidade

### SHAP (SHapley Additive exPlanations)

**VariÃ¡vel mais importante:** `Fault_Policy_Holder` (culpa do segurado)

**TOP 5 Features:**
1. Fault_Policy_Holder (importÃ¢ncia SHAP ~1.0)
2. Is_Third_Party_Fault (~0.55)
3. BasePolicy_fraud_rate (~0.55)
4. Year (~0.45)
5. RepNumber (~0.45)

**VisualizaÃ§Ãµes:**
- Summary Beeswarm (TOP 20)
- Dependence Plots
- Waterfall (casos especÃ­ficos)
- Force Plots interativos

**Detalhes:** Ver `results/shap_results/`

---

## ğŸ“ CitaÃ§Ã£o

Se vocÃª utilizar este trabalho, por favor cite:

```bibtex
@mastersthesis{rodrigues2025fraud,
  author       = {Eduardo Barbante Rodrigues},
  title        = {DetecÃ§Ã£o de Fraudes em Seguros Automotivos com Machine Learning: 
                  Uma Abordagem Integrando AvaliaÃ§Ã£o TÃ©cnica, EconÃ´mica e Interpretabilidade},
  school       = {Instituto de CiÃªncias MatemÃ¡ticas e de ComputaÃ§Ã£o, Universidade de SÃ£o Paulo},
  year         = {2025},
  address      = {SÃ£o Carlos, SP, Brasil},
  note         = {Trabalho de ConclusÃ£o de Curso},
}
```

---

## ğŸ¤ ContribuiÃ§Ãµes

ContribuiÃ§Ãµes sÃ£o bem-vindas! Por favor:

1. FaÃ§a um fork do projeto
2. Crie uma branch para sua feature (`git checkout -b feature/NovaFeature`)
3. Commit suas mudanÃ§as (`git commit -m 'Adiciona NovaFeature'`)
4. Push para a branch (`git push origin feature/NovaFeature`)
5. Abra um Pull Request

Ver [CONTRIBUTING.md](CONTRIBUTING.md) para mais detalhes.

---

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ licenciado sob a LicenÃ§a MIT - veja o arquivo [LICENSE](LICENSE) para detalhes.

---

## ğŸ‘¤ Autor

**Eduardo Barbante Rodrigues**

- GitHub: [@seu-usuario](https://github.com/seu-usuario)
- LinkedIn: [Eduardo Barbante](https://www.linkedin.com/in/seu-perfil/)
- Email: eduardo.barbante@usp.br

---

## ğŸ™ Agradecimentos

- **Profa. Dra. Cibele M. Russo** - OrientaÃ§Ã£o acadÃªmica
- **ICMC-USP** - Infraestrutura e suporte
- **Porto Seguro** - Contexto profissional e motivaÃ§Ã£o
- **Comunidade Kaggle** - Dataset Fraud Oracle

---

## ğŸ“š ReferÃªncias Principais

1. **Chawla et al. (2002)** - SMOTE: Synthetic Minority Over-sampling Technique
2. **Lundberg & Lee (2017)** - A Unified Approach to Interpreting Model Predictions (SHAP)
3. **Prokhorenkova et al. (2018)** - CatBoost: unbiased boosting with categorical features
4. **Huayanay et al. (2024)** - Performance Evaluation of Machine Learning Models with Kappa

---

## ğŸ”— Links Ãšteis

- [DocumentaÃ§Ã£o do CatBoost](https://catboost.ai/)
- [DocumentaÃ§Ã£o do SHAP](https://shap.readthedocs.io/)
- [PyCaret Documentation](https://pycaret.org/)
- [Optuna Documentation](https://optuna.org/)

---

## â­ Se este projeto foi Ãºtil, considere dar uma estrela!

---

**Ãšltima atualizaÃ§Ã£o:** Novembro 2025  
**VersÃ£o:** 1.0.0
